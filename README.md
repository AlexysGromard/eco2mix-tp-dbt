# üìä Eco2mix - Analyse de donn√©es √©nerg√©tiques

## üéØ √Ä propos

Projet d'analyse et de mod√©lisation des donn√©es de production et consommation √©lectrique en France m√©tropolitaine, d√©velopp√© dans le cadre du TP **SQL avanc√© et entrep√¥ts de donn√©es**.

Ce projet impl√©mente un **Data Warehouse** complet avec :
- üîß **dbt-core** pour la transformation et la mod√©lisation des donn√©es
- ü¶Ü **DuckDB** comme moteur analytique OLAP haute performance  
- ‚≠ê **Sch√©ma en √©toile** multi-dimensionnel (temps, g√©ographie, temp√©rature)
- üìà **Requ√™tes SQL avanc√©es** (window functions, CTE r√©cursives, CUBE/ROLLUP)

> Malgr√© de nombreuses tentatives, nous n'avons pas r√©ussi √† faire fonctionner evidence.

### üìä Donn√©es sources
- **√©CO2mix r√©gional consolid√©** : production et consommation √©lectrique par r√©gion (2013-2024)
- **Temp√©ratures quotidiennes** : relev√©s m√©t√©orologiques r√©gionaux (2016-2024)
- **12+ ans d'historique** : millions de points de mesure consolid√©s

## Pr√©requis

- Python 3.11+
- dbt-core
- dbt-duckdb
- DuckDB CLI

## Installation

```bash
# Cr√©er et activer l'environnement virtuel Python
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
# ou .venv\Scripts\activate  # Windows

# Installer les d√©pendances Python
pip install -r requirements.txt
```

## Configuration

Le projet utilise DuckDB comme base de donn√©es. La configuration se fait dans le fichier `~/.dbt/profiles.yml` :

```yaml
eco2mix:
  outputs:
    dev:
      type: duckdb
      path: eco2mix.duckdb
      extensions:
        - parquet
  target: dev
```

## Commandes dbt

```bash
# Ex√©cuter les mod√®les
dbt run

# Lancer les tests
dbt test

# Lancer les tests pour un mod√®le sp√©cifique
dbt test --select stg_eco2mix
dbt test --select dim_temps
dbt test --select fact_energie_quotidienne

# G√©n√©rer la documentation
dbt docs generate
dbt docs serve

# Compiler les mod√®les SQL en fichiers .sql
dbt compile
```

## Tests

Le projet contient des tests de qualit√© de donn√©es pour garantir l'int√©grit√© :

### Tests impl√©ment√©s
- **Tests d'unicit√©** : Cl√©s primaires des dimensions (id_temps, id_geographie, id_temperature)
- **Tests de non-nullit√©** : Colonnes essentielles (dates, codes r√©gion, mesures)
- **Tests de relations** : Int√©grit√© r√©f√©rentielle entre faits et dimensions
- **Tests de valeurs accept√©es** : Validation des statuts de donn√©es (temps_reel, consolidee, definitive)

### Lancer les tests

```bash
# Tous les tests
dbt test

# Tests par couche
dbt test --select staging.*
dbt test --select dim.*
dbt test --select mart.*

# Tests avec d√©tails en cas d'√©chec
dbt test --store-failures
```

## DuckDB

```bash
# Lancer DuckDB en mode interactif
duckdb eco2mix.duckdb

# Lancer DuckDB avec interface web
duckdb eco2mix.duckdb -ui
```

L'interface web DuckDB sera accessible sur http://localhost:8080

## Structure du projet

```
‚îú‚îÄ‚îÄ models/           # Mod√®les dbt
‚îÇ   ‚îú‚îÄ‚îÄ staging/      # Couche de staging (sources brutes)
‚îÇ   ‚îú‚îÄ‚îÄ intermediate/ # Couche interm√©diaire (transformations)
‚îÇ   ‚îú‚îÄ‚îÄ dim/          # Tables de dimensions
‚îÇ   ‚îî‚îÄ‚îÄ mart/         # Tables de faits (sch√©ma en √©toile)
‚îú‚îÄ‚îÄ analyses/         # Requ√™tes analytiques SQL avanc√©es
‚îú‚îÄ‚îÄ seeds/            # Donn√©es statiques
‚îú‚îÄ‚îÄ tests/            # Tests personnalis√©s
‚îú‚îÄ‚îÄ macros/           # Macros Jinja r√©utilisables
‚îî‚îÄ‚îÄ eco2mix.duckdb    # Base de donn√©es DuckDB
```

## Analyses SQL avanc√©es

Les requ√™tes SQL avanc√©es r√©pondant aux questions du sujet se trouvent dans le dossier [`analyses/`](analyses/) :

### Section 3 - Exploration

1. **[Groupement et agr√©gation simples](analyses/01_groupement_aggregation.sql)** : Production et consommation (GWh) avec min/max/moyenne instantan√©es (MW), par mois et par r√©gion

2. **[Pivot](analyses/02_pivot_consommation.sql)** : Consommation journali√®re d√©taill√©e par r√©gion (format pivot avec une colonne par r√©gion)

3. **[Fen√™tre glissante](analyses/03_fenetre_glissante.sql)** : Consommation r√©gionale sur 30 jours glissants avec window functions

4. **[Variation](analyses/04_variation_consommation.sql)** : Top 20 des plus grands √©carts de consommation quotidienne d'un jour √† l'autre

5. **[Quantit√© cumul√©e](analyses/05_quantite_cumulee.sql)** : Date de d√©passement de la production renouvelable annuelle par la consommation

6. **[Calcul de point fixe](analyses/06_calcul_point_fixe.sql)** : Les 3 plus longues s√©quences d'augmentation de consommation instantan√©e (CTE r√©cursive)

7. **Construction du cube** : Consommation agr√©g√©e par dimensions temporelles et g√©ographiques
   - [7a - ROLLUP](analyses/07a_cuboide_rollup.sql)
   - [7b - GROUPING SETS](analyses/07b_cuboide_grouping_sets.sql)
   - [7c - CUBE](analyses/07c_cuboide_cube.sql)

### Section 4 - Entrep√¥t de donn√©es

Le cubo√Øde par mois, quart et intervalle de temp√©rature se trouve dans :
- **[Cubo√Øde mois/quart/temp√©rature](analyses/cuboide_avec_grouping_sets.sql)**

## Sch√©ma en √©toile

Le projet impl√©mente un sch√©ma en √©toile multi-dimensionnel avec :

### Tables de dimensions
- **[dim_temps](models/dim/dim_temps.sql)** : Dimension temporelle (jour, mois, saison, ann√©e)
- **[dim_geographie](models/dim/dim_geographie.sql)** : Dimension g√©ographique (r√©gion, zone, pays)
- **[dim_temperature](models/dim/dim_temperature.sql)** : Dimension temp√©rature (intervalle de temp√©rature)

### Table de faits
- **[fact_energie_quotidienne](models/mart/fact_energie_quotidienne.sql)** : Mesures quotidiennes de production et consommation par r√©gion

## Sources de donn√©es

- [√©CO2mix r√©gional consolid√© et d√©finitif](https://odre.opendatasoft.com/explore/dataset/eco2mix-regional-cons-def/) (2013-2024)
- [Temp√©rature quotidienne r√©gionale](https://odre.opendatasoft.com/explore/dataset/temperature-quotidienne-regionale/) (2016-2024)
- [√©CO2mix r√©gional temps r√©el](https://odre.opendatasoft.com/explore/dataset/eco2mix-regional-tr/) (pour mises √† jour incr√©mentales)

## Mise √† Jour Incr√©mentale de l'Entrep√¥t

### Principe

Mise √† jour incr√©mentale avec gestion du cycle : **temps_reel** ‚Üí **consolidee** ‚Üí **definitive**

**R√®gle** : Pour une m√™me date/r√©gion, la donn√©e avec le statut de priorit√© la plus √©lev√©e est conserv√©e (definitive=3, consolidee=2, temps_reel=1).

### Architecture

```
eco2mix-regional-tr.parquet
    ‚Üì
stg_eco2mix_temps_reel (view)
    ‚Üì
int_eco2mix_incremental (incremental) ‚Üê Agr√©gation journali√®re + gestion statuts
    ‚Üì
fact_energie_quotidienne_incremental (incremental) ‚Üê Fusion avec donn√©es d√©finitives
```

### Utilisation

#### Premi√®re ex√©cution
```bash
dbt run --select fact_energie_quotidienne_incremental --full-refresh
```

#### Mise √† jour quotidienne
```bash
dbt run --select fact_energie_quotidienne_incremental
```

Ne traite que les nouvelles donn√©es (filtrage sur `date_integration`), gain ~30√ó.

#### Exemple de transition de statut
```
Jour J   : 2025-01-15, √éle-de-France, temps_reel, 5000 GWh
Jour J+1 : 2025-01-15, √éle-de-France, consolidee, 5100 GWh
R√©sultat : La version consolid√©e remplace la version temps_reel
```

### Tests

```sql
-- V√©rifier l'unicit√©
SELECT date, code_insee_region, COUNT(*) 
FROM {{ ref('fact_energie_quotidienne_incremental') }}
GROUP BY date, code_insee_region
HAVING COUNT(*) > 1
```

```bash
dbt test --select fact_energie_quotidienne_incremental
```

### Monitoring

```sql
-- Distribution par statut
SELECT statut_donnee, COUNT(*), MIN(date), MAX(date)
FROM fact_energie_quotidienne_incremental
GROUP BY statut_donnee;
```

### Composants

- **sources.yml** : D√©claration de `eco2mix-regional-tr.parquet`
- **stg_eco2mix_temps_reel.sql** : Nettoyage + ajout `statut_donnee` et `date_integration`
- **int_eco2mix_incremental.sql** : Agr√©gation journali√®re avec gestion priorit√©s
- **fact_energie_quotidienne_incremental.sql** : Table de fait finale
- **macros/incremental_helpers.sql** : Fonctions utilitaires

## Documentation compl√®te

Le sujet complet du TP est disponible dans [sujet_eco2mix_dbt_part2.md](sujet_eco2mix_dbt_part2.md).
